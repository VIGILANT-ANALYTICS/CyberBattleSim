{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88befde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# %%\n",
    "class TinyMaze3x3(gym.Env):\n",
    "    \"\"\"A tiny 3x3 maze with hardcoded walls. Keep it simple.\n",
    "\n",
    "    Start=(0,0), Goal=(2,2), Walls={(1,1),(1,0)}\n",
    "    Observation: int in [0..8] (r*3 + c)\n",
    "    Actions: 0=UP, 1=RIGHT, 2=DOWN, 3=LEFT\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"ansi\", \"human\", \"rgb_array\"]}\n",
    "\n",
    "    UP, RIGHT, DOWN, LEFT = 0, 1, 2, 3\n",
    "\n",
    "    def __init__(self, render_mode: Optional[str] = None):\n",
    "        super().__init__()\n",
    "        self.n = 3\n",
    "        self.start = (0, 0)\n",
    "        self.goal = (2, 2)\n",
    "        self.walls = {(1, 1), (1, 0)}  # <â€” edit these if you want\n",
    "        self.max_steps = 10\n",
    "\n",
    "        # There are 4 unique actions / Only one can be chosen at any time\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "        # The game state is a single number up to n**2\n",
    "        self.observation_space = spaces.Discrete(self.n * self.n)\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "        self.agent_pos = self.start\n",
    "        self.step_count = 0\n",
    "\n",
    "    # ---- helpers ----\n",
    "    # Simply returns encoding of the position in the maze\n",
    "    def _to_obs(self, pos: Tuple[int, int]) -> int:\n",
    "        r, c = pos\n",
    "        return r * self.n + c\n",
    "\n",
    "    def _in_bounds(self, r: int, c: int) -> bool:\n",
    "        return 0 <= r < self.n and 0 <= c < self.n\n",
    "\n",
    "    def _move(self, action: int, pos: Tuple[int, int]) -> Tuple[Tuple[int, int], bool]:\n",
    "        r, c = pos\n",
    "        if action == self.UP:\n",
    "            cand = (r - 1, c)\n",
    "        elif action == self.RIGHT:\n",
    "            cand = (r, c + 1)\n",
    "        elif action == self.DOWN:\n",
    "            cand = (r + 1, c)\n",
    "        elif action == self.LEFT:\n",
    "            cand = (r, c - 1)\n",
    "        else:\n",
    "            return pos, False\n",
    "        if self._in_bounds(*cand) and cand not in self.walls:\n",
    "            return cand, True\n",
    "        return pos, False\n",
    "\n",
    "    # ---- core API ----\n",
    "    # Same as ml-agents OnEpisodeStart();\n",
    "    # Goal here is to clean and reset all the environment\n",
    "    def reset(\n",
    "        self, *, seed: Optional[int] = None, options: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        # Reposition agent to starting cells\n",
    "        self.agent_pos = self.start\n",
    "        # Reset step counter\n",
    "        self.step_count = 0\n",
    "        # Returning game state + info (useless for now, but you can use it to create some nice analysis)\n",
    "        return self._to_obs(self.agent_pos), {\"pos\": self.agent_pos, \"goal\": self.goal}\n",
    "\n",
    "    def step(self, action: int):\n",
    "        assert self.action_space.contains(action)\n",
    "        self.step_count += 1\n",
    "\n",
    "        new_pos, moved = self._move(action, self.agent_pos)\n",
    "        self.agent_pos = new_pos\n",
    "\n",
    "        reward = -0.01\n",
    "        if not moved:\n",
    "            reward += -0.05\n",
    "\n",
    "        terminated = self.agent_pos == self.goal\n",
    "        truncated = (self.step_count >= self.max_steps) and not terminated\n",
    "\n",
    "        obs = self._to_obs(self.agent_pos)\n",
    "        info = {\"pos\": self.agent_pos, \"moved\": moved, \"step\": self.step_count}\n",
    "        if terminated:\n",
    "            reward += 1.0\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        fig, ax = plt.subplots(figsize=(3, 3))\n",
    "        ax.set_xlim(-0.5, self.n - 0.5)\n",
    "        ax.set_ylim(-0.5, self.n - 0.5)\n",
    "        ax.set_xticks(range(self.n))\n",
    "        ax.set_yticks(range(self.n))\n",
    "        ax.grid(True)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "        # Draw walls\n",
    "        for r, c in self.walls:\n",
    "            ax.add_patch(plt.Rectangle((c - 0.5, r - 0.5), 1, 1))\n",
    "\n",
    "        # Draw start, goal, agent\n",
    "        sr, sc = self.start\n",
    "        gr, gc = self.goal\n",
    "        ar, ac = self.agent_pos\n",
    "        ax.text(sc, sr, \"S\", ha=\"center\", va=\"center\", fontsize=16, color=\"green\")\n",
    "        ax.text(gc, gr, \"G\", ha=\"center\", va=\"center\", fontsize=16, color=\"red\")\n",
    "        ax.text(ac, ar, \"A\", ha=\"center\", va=\"center\", fontsize=16, color=\"blue\")\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            # Video like rendering\n",
    "            # Jupyter-friendly update\n",
    "            from IPython.display import display, clear_output\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            display(fig)\n",
    "            plt.close(fig)\n",
    "            return None\n",
    "        else:\n",
    "            plt.close(fig)\n",
    "            return fig\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c7aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state, parent) -> None:\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "\n",
    "        self.n = 0\n",
    "        self.q = 0\n",
    "\n",
    "    def eval(self):\n",
    "        # return ucb\n",
    "        return 0\n",
    "\n",
    "    def expand(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, env) -> None:\n",
    "\n",
    "        self.root = Node()\n",
    "\n",
    "    def select(self):\n",
    "        # from current node, find best leaf\n",
    "\n",
    "    def expand(self, node):\n",
    "        # Initialize all new child nodes\n",
    "        pass\n",
    "\n",
    "    def simulate(self, state):\n",
    "        # run random game from \"state\"\n",
    "        pass\n",
    "\n",
    "    def backpropagate(self, node, reward):\n",
    "        pass\n",
    "        # self.q += reward\n",
    "        # if self.parent:\n",
    "        #    self.parent.backpropagate(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6576d92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = TinyMaze3x3(render_mode=\"human\")\n",
    "# Obs contains the game state (which is also the NN/Agent input 99.99% of the times)\n",
    "obs, info = env.reset(seed=0)\n",
    "# Done keeps track of whether the game is done or not\n",
    "done = False\n",
    "#\n",
    "while not done:\n",
    "    # try a random policy\n",
    "    a = env.action_space.sample()\n",
    "    print(a)\n",
    "    obs, reward, terminated, truncated, info = env.step(a)\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682940c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cybershield",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
